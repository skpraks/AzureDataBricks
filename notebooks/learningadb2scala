// Databricks notebook source
val userName = dbutils.secrets.get(scope = "training-scope", key = "adbclientsecret")

print(userName)

// COMMAND ----------

spark.conf.set("fs.azure.account.auth.type.adbdlsstoragev3.dfs.core.windows.net", "OAuth")
spark.conf.set("fs.azure.account.oauth.provider.type.adbdlsstoragev3.dfs.core.windows.net", "org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider")
spark.conf.set("fs.azure.account.oauth2.client.id.adbdlsstoragev3.dfs.core.windows.net", "02f67ffc-2e16-43b1-bc74-e819ba0581c2")
spark.conf.set("fs.azure.account.oauth2.client.secret.adbdlsstoragev3.dfs.core.windows.net", userName)
spark.conf.set("fs.azure.account.oauth2.client.endpoint.adbdlsstoragev3.dfs.core.windows.net", "https://login.microsoftonline.com/72f988bf-86f1-41af-91ab-2d7cd011db47/oauth2/token")
spark.conf.set("fs.azure.createRemoteFileSystemDuringInitialization", "true")
dbutils.fs.ls("abfss://data@adbdlsstoragev3.dfs.core.windows.net/")
spark.conf.set("fs.azure.createRemoteFileSystemDuringInitialization", "false")

// COMMAND ----------

// MAGIC %sh 
// MAGIC 
// MAGIC wget -P /tmp https://raw.githubusercontent.com/Azure/usql/master/Examples/Samples/Data/json/radiowebsite/small_radio_json.json

// COMMAND ----------

dbutils.fs.cp("file:///tmp/small_radio_json.json", "abfss://data@adbdlsstoragev3.dfs.core.windows.net/")

// COMMAND ----------

// MAGIC %sql
// MAGIC DROP TABLE IF EXISTS radio_sample_data;
// MAGIC CREATE TABLE radio_sample_data
// MAGIC USING json
// MAGIC OPTIONS (
// MAGIC  path  "abfss://data@adbdlsstoragev3.dfs.core.windows.net/small_radio_json.json"
// MAGIC )

// COMMAND ----------

// MAGIC %sql
// MAGIC SELECT * FROM radio_sample_data

// COMMAND ----------

